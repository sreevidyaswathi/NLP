# -*- coding: utf-8 -*-
"""NLP_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dl50Z9u_XQgSNC89dJLb8Kylu4LCd_2W
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download("stopwords")

df= pd.read_csv('/content/sample_data/K8 Reviews v0.2.csv')

df.describe()

df.info()

df.isna().sum()

df["review"] = df.review.apply(lambda x: x.lower())

reviewList=[]
df["review"].apply(lambda x: reviewList.append(x))

len(reviewList)

reviewList[1]

from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet,stopwords
stopwords= set(stopwords.words('english'))
tokenizer = nltk.RegexpTokenizer(r"\w+")
from nltk.stem import WordNetLemmatizer
lemmatizer= WordNetLemmatizer()

"""## Preprocessing the review list"""

def Tokenization_and_posTagging(reviewList):
  Tokenized_POSTagged_list=[]
  
  #Tokenizing (Removing Punctuation)
  for review in reviewList:
        tokenized_review=tokenizer.tokenize(review)
        gram_tagged_review=nltk.pos_tag(tokenized_review)
        Tokenized_POSTagged_list.append(gram_tagged_review)
  return Tokenized_POSTagged_list

def FilterNouns(Tokenized_POSTagged_list):
  for i in np.arange(0,5):
    NounTaggedList=[]
    for Taglist in Tokenized_POSTagged_list:
      for eachtag  in Taglist:
           if(("NN" in eachtag[1])):
               if(eachtag[0] in stopwords):
                   Taglist.remove(eachtag)  
               else:
                   pass
           else:
               Taglist.remove(eachtag)
      NounTaggedList.append(Taglist)
  # print("After Tagging and filtering Nouns:" , NounTaggedList)
  return NounTaggedList


def lemmatization(NounTaggedList):
  #Removing the empty lists and lemmatizing the toeknized, pos tagged words
  for li in NounTaggedList:
    if( li== []):
      NounTaggedList.remove(li)
    else:
      for worddict in li:
        lemmatizer.lemmatize(worddict[0], "n")
  # print("After Lemming:",NounTaggedList)
  return NounTaggedList

def preprocessed_text(NounTaggedList):
  #removing the tags and converting the tuples to list
  each_list=[]
  preprocessed_list=[]
  for li in NounTaggedList:
    for wordict in li:
      each_list.append(wordict[0])
    preprocessed_list.append(each_list)
    each_list=[]
  # print(preprocessed_list)
  return preprocessed_list

Tokenized_POSTagged_list=Tokenization_and_posTagging(reviewList)
len(Tokenized_POSTagged_list)

NounTaggedList=FilterNouns(Tokenized_POSTagged_list)
NounTaggedList

NounTaggedList=lemmatization(NounTaggedList)
len(NounTaggedList)

preprocessedText=preprocessed_text(NounTaggedList)

len(preprocessedText)

"""## Creating an Lda model on preprocessed Text for topic modelling"""

import gensim

from gensim import corpora

dictionary= corpora.Dictionary(preprocessedText)

dictionary

doc_term_matrix= [dictionary.doc2bow(doc) for doc in preprocessedText]

doc_term_matrix

lda= gensim.models.ldamodel.LdaModel

"""# Considering the number of topics as 12"""

ldamodel = lda(doc_term_matrix, num_topics=12, id2word = dictionary, passes=50)

ldamodel.print_topics(num_topics=12, num_words=4)

"""## Clear visualization of Lda model with number of topics taken as 12"""

import pyLDAvis
import os
import pickle 
import pyLDAvis.gensim_models as gensimvis

# Visualize the topics
num_topics=12
pyLDAvis.enable_notebook()
LDAvis_data_filepath = os.path.join('/content/sample_data/ldavis_prepared_'+str(num_topics))
# # this is a bit time consuming - make the if statement True
# # if you want to execute visualization prep yourself
if 1 == 1:
    LDAvis_prepared = gensimvis.prepare(ldamodel, doc_term_matrix, dictionary)
    with open(LDAvis_data_filepath, 'wb') as f:
        pickle.dump(LDAvis_prepared, f)
# load the pre-prepared pyLDAvis data from disk
with open(LDAvis_data_filepath, 'rb') as f:
    LDAvis_prepared = pickle.load(f)
pyLDAvis.save_html(LDAvis_prepared, '/content/sample_data/ldavis_prepared_'+ str(num_topics) +'.html')
LDAvis_prepared

"""The 12 clusters mainly talk about the battery/heating/charging issues and phone's camera quality issues

# coherence score (c_v metric) for number of topics = 12
"""

# Compute Coherence Score using c_v
from gensim.models.coherencemodel import CoherenceModel
coherence_model_lda = CoherenceModel(model=ldamodel, texts=preprocessedText, dictionary=dictionary, coherence='c_v')
coherence_lda = coherence_model_lda.get_coherence()
print('\nCoherence Score: ', coherence_lda)

"""# Now computing the coherance values for different number of topic ranging from 2 - 40 for finding out the optimal topic"""

def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):
    """
    Compute c_v coherence for various number of topics

    Parameters:
    ----------
    dictionary : Gensim dictionary
    corpus : Gensim corpus
    texts : List of input texts
    limit : Max num of topics

    Returns:
    -------
    model_list : List of LDA topic models
    coherence_values : Coherence values corresponding to the LDA model with respective number of topics
    """
    coherence_values = []
    model_list = []
    for num_topics in range(start, limit, step):
        model=lda(corpus=corpus, id2word=dictionary, num_topics=num_topics)
        model_list.append(model)
        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')
        coherence_values.append(coherencemodel.get_coherence())

    return model_list, coherence_values

model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=preprocessedText, start=2, limit=40, step=6)
# Show graph
import matplotlib.pyplot as plt
limit=40; start=2; step=6;
x = range(start, limit, step)
plt.plot(x, coherence_values)
plt.xlabel("Num Topics")
plt.ylabel("Coherence score")
plt.legend(("coherence_values"), loc='best')
plt.show()

"""Graph clearly shows that coherance value of the model is high when num of topics is 2.

## Hence **the optimal topic count is 2** 
## 1.Battery heating issues while charging
## 2.Camera quality issues
"""

ldamodel = lda(doc_term_matrix, num_topics=2, id2word = dictionary, passes=50)

"""## Calculating the coherence score for the optimal topic count as 2


"""

# Compute Coherence Score using c_v
from gensim.models.coherencemodel import CoherenceModel
coherence_model_lda = CoherenceModel(model=ldamodel, texts=preprocessedText, dictionary=dictionary, coherence='c_v')
coherence_lda = coherence_model_lda.get_coherence()
print('\nCoherence Score: ', coherence_lda)

"""# Clear visualization of the Lda model with optimal topic count as 2"""

import pyLDAvis
import os
import pickle 
import pyLDAvis.gensim_models as gensimvis

# Visualize the topics
num_topics=2
pyLDAvis.enable_notebook()
LDAvis_data_filepath = os.path.join('/content/sample_data/ldavis_prepared_'+str(num_topics))
# # this is a bit time consuming - make the if statement True
# # if you want to execute visualization prep yourself
if 1 == 1:
    LDAvis_prepared = gensimvis.prepare(ldamodel, doc_term_matrix, dictionary)
    with open(LDAvis_data_filepath, 'wb') as f:
        pickle.dump(LDAvis_prepared, f)
# load the pre-prepared pyLDAvis data from disk
with open(LDAvis_data_filepath, 'rb') as f:
    LDAvis_prepared = pickle.load(f)
pyLDAvis.save_html(LDAvis_prepared, '/content/sample_data/ldavis_prepared_'+ str(num_topics) +'.html')
LDAvis_prepared

"""From the above visualization, we can clearly understand that the reviews for the k8 - lenovo note , mainly talk about the below two topics
## 1. Phone's Camera quality issue, camera performance, pricing of note K8.
The top 10 words that corresponds to first topic:

*   Phone
*   Camera
*   battery
*   quality
*   note
*   performance
*   price
*   Lenovo
*   features
*   screen

## 2. Phone's Battery heating issue, heating issue while charging, amazon service issues and pricing of the product.

The top 10 words that corresponds to first topic:

*   Product
*   problem
*   mobile
*   battery
*   money
*   amazon
*   heating
*   issue
*   service
*   charger
"""

